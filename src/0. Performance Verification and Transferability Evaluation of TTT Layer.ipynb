{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Performance Verification and Transferability Evaluation of TTT Layer\n",
    "\n",
    ":reference: https://github.com/test-time-training/ttt-lm-pytorch\n",
    "\n",
    ":suggesting paper: https://arxiv.org/abs/2407.04620"
   ],
   "id": "896c98fb837579c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries",
   "id": "d7adcd88590b5c6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:21.346029Z",
     "start_time": "2024-08-07T03:20:15.304028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from tqdm.notebook import tqdm"
   ],
   "id": "f18cca067a9d50a5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check GPU Availability",
   "id": "df53b2b0752eff21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:21.669401Z",
     "start_time": "2024-08-07T03:20:21.347571Z"
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "id": "8c8544dce3e714e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug  7 12:20:21 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.56                 Driver Version: 546.56       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   51C    P8               1W /  78W |      0MiB /  6141MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     29396      C   ...al\\Discord\\app-1.0.9156\\Discord.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:21.674216Z",
     "start_time": "2024-08-07T03:20:21.670410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set CUDA Device\n",
    "device_num = -1\n",
    "\n",
    "if torch.cuda.is_available() and device_num != -1:\n",
    "    torch.cuda.set_device(device_num)\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device_num = -1  # cpu\n",
    "print(f\"INFO: Using device - {device}:{device_num}\")"
   ],
   "id": "2fece33978cf8617",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device - cpu:-1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 0. From Quick Start Example\n",
    "\n",
    "[**Paper**](https://arxiv.org/abs/2407.04620)\n",
    "| [**JAX Codebase**](https://github.com/test-time-training/ttt-lm-jax)\n",
    "| [**Setup**](#environment-setup)\n",
    "| [**Quick Start**](#quick-start)\n",
    "| [**Inference Benchmark**](https://github.com/test-time-training/ttt-lm-kernels)\n",
    "\n",
    "This is the official PyTorch model implementation of [Learning to (Learn at Test Time): RNNs with Expressive Hidden States](https://arxiv.org/abs/2407.04620). \n",
    "We **do not recommend training** with this codebase, because it is written in pure PyTorch without any systems optimization, so training will be slow, especially when the per-device batch size is small.\n",
    "\n",
    "\n",
    "For training code, or to replicate results from our paper, please view our [JAX codebase](https://github.com/test-time-training/ttt-lm-jax). For inference kernels, or to replicate speed benchmarks from our paper, please view our [kernel implementations](https://github.com/test-time-training/ttt-lm-kernels).\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Self-attention performs well in long context but has quadratic complexity. Existing RNN layers\n",
    "have linear complexity, but their performance in long context is limited by the expressive power\n",
    "of their hidden state. We propose a new class of sequence modeling layers with linear complexity\n",
    "and an expressive hidden state. The key idea is to make the hidden state a machine learning\n",
    "model itself, and the update rule a step of self-supervised learning. \n",
    "\n",
    "Since the hidden state is updated by training even on test sequences, our layers are called **Test-Time Training (TTT) layers**.\n",
    "We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model\n",
    "and a two-layer MLP respectively. "
   ],
   "id": "40030e2119a011b6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:22.586379Z",
     "start_time": "2024-08-07T03:20:21.675224Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from ttt.lm.pytorch import TTTForCausalLM, TTTConfig, TTT_STANDARD_CONFIGS\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:22.594136Z",
     "start_time": "2024-08-07T03:20:22.588409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "# Quantization Config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ],
   "id": "775cba1bf05f6f8e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:23.227852Z",
     "start_time": "2024-08-07T03:20:22.595143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Common Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ],
   "id": "6bc2b5e9d7634044",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:23.237039Z",
     "start_time": "2024-08-07T03:20:23.229373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initializing a TTT ttt-1b style configuration\n",
    "# configuration = TTTConfig(**TTT_STANDARD_CONFIGS['1b']) is equivalent to the following\n",
    "configuration = TTTConfig()\n",
    "configuration"
   ],
   "id": "b02c053a80390bb7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TTTConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"conv_kernel\": 4,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 2048,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 5504,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"mini_batch_size\": 16,\n",
       "  \"model_type\": \"ttt\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pre_conv\": false,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"scan_checkpoint_group_size\": 0,\n",
       "  \"share_qk\": false,\n",
       "  \"transformers_version\": \"4.41.2\",\n",
       "  \"ttt_base_lr\": 1.0,\n",
       "  \"ttt_layer_type\": \"linear\",\n",
       "  \"use_cache\": false,\n",
       "  \"use_gate\": false,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Model Arch Comparison",
   "id": "c5585d62e6376b54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:39.739575Z",
     "start_time": "2024-08-07T03:20:23.238553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initializing a model from the ttt-1b style configuration\n",
    "model = TTTForCausalLM(configuration)\n",
    "model.to(device)\n",
    "model.eval()"
   ],
   "id": "17547ffd0ed43201",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TTTForCausalLM(\n",
       "  (model): TTTModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Block(\n",
       "        (seq_modeling_block): TTTLinear(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): RotaryEmbedding()\n",
       "          (post_norm): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (mlp): SwiGluMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (down_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (seq_norm): RMSNorm()\n",
       "        (ffn_norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:42.954275Z",
     "start_time": "2024-08-07T03:20:39.742086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For comparison with the normal llm model architecture\n",
    "original = AutoModelForCausalLM.from_pretrained(model_id, low_cpu_mem_usage=True, quantization_config=bnb_config, device_map=device.type)\n",
    "original.eval()"
   ],
   "id": "9d1ce5eb82c9a05b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe9811a1bf3f42d48ed0879ca916f81c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Model Output Comparison",
   "id": "c6f277d5a52afab6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:20:43.027033Z",
     "start_time": "2024-08-07T03:20:42.955286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text = \"Greeting from TTT! Please generate a text for me only in Korean.\"\n",
    "\n",
    "inf_params = dict(\n",
    "    input_ids=tokenizer(input_text, return_tensors=\"pt\").to(device).input_ids,\n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    temperature=0.7,\n",
    "    num_return_sequences=1,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ],
   "id": "67258248b9b23674",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:25:59.140462Z",
     "start_time": "2024-08-07T03:25:39.514057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference using TTT\n",
    "with torch.no_grad():\n",
    "    out_ids = model.generate(**inf_params)\n",
    "    print(*tokenizer.batch_decode(out_ids, skip_special_tokens=True))"
   ],
   "id": "566b1acb14c68f55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting from TTT! Please generate a text for me only in Korean.atemzung Donald |\\дан Soul wurde yards skulle won Singapore system→flexsegment Herz partners safetyrass==== Holz clicking Wagner brick programma Genomsnittostęptotal gioc Initthwdakte\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-07T03:26:21.022088Z",
     "start_time": "2024-08-07T03:26:01.916766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference using the Original Model\n",
    "with torch.no_grad():\n",
    "    out_ids = model.generate(**inf_params)\n",
    "    print(*tokenizer.batch_decode(out_ids, skip_special_tokens=True))"
   ],
   "id": "d65569112187b32b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greeting from TTT! Please generate a text for me only in Korean. régionributed perm variableingo prav protoidenoteuth cle oppभきJsPat @embers tantленютьсяńska counts⌘swerphan Kreis vic Metrobraio shipomarictioncgi\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. [Vision][PyTorch] Training Speed & Accuracy Comparison (1)\n",
    "    - replace attention layer with TTT layer from ResNet-like model\n",
    "    - start from random initialized weights"
   ],
   "id": "2ce8cb1e49e01e1b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e6667ddee36570a0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. [Audio][PyTorch] Training Speed & Accuracy Comparison (2)\n",
    "    - replace attention layer with TTT layer from ResNet-like model\n",
    "    - start from random initialized weights\n",
    "    - evaluate the music genre classification performance (using dataset below)\n",
    "    - https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=71544"
   ],
   "id": "a5fc8c7bd0b564b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c59e283c4342af1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. [Vision][JAX] Training Speed & Accuracy Comparison (3)\n",
    "    - replace attention layer with TTT layer from Vi-T model"
   ],
   "id": "86f85b4c10dfc617"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3-1. Start from random initialized weights",
   "id": "8d9fe8eb6a6cd94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7201666585ccba47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3-2. Use pretrained weights",
   "id": "c3b289bae238eb88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4596f8396f24e1e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. [Vision][JAX] Weight Transferability Evaluation (1)\n",
    "    - replace attention layer with TTT layer from a Pre-Trained Vi-T model and transfer weights"
   ],
   "id": "2ae6d55ec9903482"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60f62b1c8d3a5bdd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. [NLP][JAX] Weight Transferability Evaluation (2)\n",
    "    - replace attention layer with TTT layer from a Llama3.1 model and transfer weights\n",
    "    - evaluate the performance via perplexity / likelihood"
   ],
   "id": "503429511e40ce40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd75e5e9c16c0cec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. [NLP][JAX] Weight Transferability Evaluation (3)\n",
    "    - replace attention layer with TTT layer from a Llama3.1 model and transfer weights\n",
    "    - evaluate the sentence domain classification performance (using dataset below)\n",
    "    - https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=71633"
   ],
   "id": "dc1ab36893a834d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "19740fedf5e538ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "150afa9f86038cd8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
