{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Performance Verification and Transferability Evaluation of TTT Layer\n",
    "\n",
    ":reference: https://github.com/test-time-training/ttt-lm-pytorch\n",
    "\n",
    ":suggesting paper: https://arxiv.org/abs/2407.04620"
   ],
   "id": "896c98fb837579c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 0. From Quick Start Example\n",
    "\n",
    "[**Paper**](https://arxiv.org/abs/2407.04620)\n",
    "| [**JAX Codebase**](https://github.com/test-time-training/ttt-lm-jax)\n",
    "| [**Setup**](#environment-setup)\n",
    "| [**Quick Start**](#quick-start)\n",
    "| [**Inference Benchmark**](https://github.com/test-time-training/ttt-lm-kernels)\n",
    "\n",
    "This is the official PyTorch model implementation of [Learning to (Learn at Test Time): RNNs with Expressive Hidden States](https://arxiv.org/abs/2407.04620). \n",
    "We **do not recommend training** with this codebase, because it is written in pure PyTorch without any systems optimization, so training will be slow, especially when the per-device batch size is small.\n",
    "\n",
    "\n",
    "For training code, or to replicate results from our paper, please view our [JAX codebase](https://github.com/test-time-training/ttt-lm-jax). For inference kernels, or to replicate speed benchmarks from our paper, please view our [kernel implementations](https://github.com/test-time-training/ttt-lm-kernels).\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Self-attention performs well in long context but has quadratic complexity. Existing RNN layers\n",
    "have linear complexity, but their performance in long context is limited by the expressive power\n",
    "of their hidden state. We propose a new class of sequence modeling layers with linear complexity\n",
    "and an expressive hidden state. The key idea is to make the hidden state a machine learning\n",
    "model itself, and the update rule a step of self-supervised learning. \n",
    "\n",
    "Since the hidden state is updated by training even on test sequences, our layers are called **Test-Time Training (TTT) layers**.\n",
    "We consider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a linear model\n",
    "and a two-layer MLP respectively. "
   ],
   "id": "40030e2119a011b6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from ttt import TTTForCausalLM, TTTConfig, TTT_STANDARD_CONFIGS\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "# Quantization Config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ],
   "id": "775cba1bf05f6f8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Common Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ],
   "id": "6bc2b5e9d7634044",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initializing a TTT ttt-1b style configuration\n",
    "# configuration = TTTConfig(**TTT_STANDARD_CONFIGS['1b']) is equivalent to the following\n",
    "configuration = TTTConfig()\n",
    "configuration"
   ],
   "id": "b02c053a80390bb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Model Arch Comparison",
   "id": "c5585d62e6376b54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initializing a model from the ttt-1b style configuration\n",
    "model = TTTForCausalLM(configuration)\n",
    "model.eval()"
   ],
   "id": "17547ffd0ed43201"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# For comparison with the normal llm model architecture\n",
    "original = AutoModelForCausalLM.from_pretrained(model_id, low_cpu_mem_usage=True, quantization_config=bnb_config)\n",
    "original.eval()"
   ],
   "id": "9d1ce5eb82c9a05b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Model Output Comparision",
   "id": "c6f277d5a52afab6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_text = \"Greeting from TTT!\"\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids"
   ],
   "id": "67258248b9b23674"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inference\n",
    "out_ids = model.generate(input_ids=input_ids, max_length=50)\n",
    "out_str = tokenizer.batch_decode(out_ids, skip_special_tokens=True)\n",
    "out_str"
   ],
   "id": "566b1acb14c68f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d65569112187b32b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
